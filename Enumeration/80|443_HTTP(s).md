# Inspect HTML Code of Webpapges
- Should be done on each page you are able to navigate to.
- Focus on where there are any usernames / passwords, comments / notes, extraneous / non-prod code, or hidden values in the HTML.

# Evaluate IP vs. Hostname Resolution
- Sometimes hostname-based routing is applied in the web server service in which you get different results if you navigate to port 80 with the IP or the hostname. 
- Try both IP and Hostname to see if this is the case to capture all enumeration possibilities. 
1. Identify the hostname of the box – generally through the 'CommonName' field of the SSL cert for web pages with HTTPS running (generally over port 443). 
2. Add the mapping between IP and hostname into the attacker machine host file. 
```
vi /etc/hosts/
[IP address]         [hostname] 
```
3. Access the webpage through the IP address over both port 80 and 443. 
4. Access the webpage through the host name over both port 80 and 443. 
- If they both result in the same page, then there is no hostname-based routing applicable.

# Evaluate HTTP/S Usage
- Generally HTTP works over port 80 and HTTPS works over port 443.  However, this isn't always the case.  Sometimes there is different content served over different protocols through either of these ports. 
1. Access port 80 over HTTP and HTTPS protocols. 
2. Access port 443 over HTTP and HTTPS protocols

# Evaluate SSL Cert Details
- Sites that allow SSL/TLS over HTTPS have a Public Certificate that is viewable by all clients. 
1. Navigate to the webpage using the HTTPS protocol. 
2. Click on the lock in the address bar. 
3. More Information > Security > View Certificate > Details 
4. Hostname > Certificate > Issuer 
  - Email address with a username in the 'E' field. 
  - Hostname in the 'CN' field. 
5. Hostname > Certificate > Subject 
  - Email address with a username in the 'E' field. 
  - Hostname in the 'CN' field.

# Evaluate Code Support Beyond HTML (ippsec:FriendZone)
1. Try to append /index.html and /index.php to the end of the IP address of the web server.
2. If index.html resolves but index.php doesn't, then the website likely doesn't support PHP and is likely just static HTML.  To speed up recon, the web pages are unlikely to have significant attack surface.  If .php does resovle, it's worth further enumeration of the website.

# Evaluate Robots.txt File (ippsec=Irked)
- This is included at the root of the web server address to indicate which pages of the website not to be indexed by search engines like Google.
- If it exists, it usually discloses pages, directories, and extensions that the web site creator didn't want the general public knowing about through using a search engine.
```
http://[IP / Hostname]:[port]/robots.txt
```

# Evaluate for Heartbleed
- OpenSSL 1.0.1 through 1.0.1f (inclusive) are vulnerable.
- OpenSSL 1.0.1g is NOT vulnerable.
- OpenSSL 1.0.0 branch is NOT vulnerable.
- OpenSSL 0.9.8 branch is NOT vulnerable.
```
sslscan [IP]:443
```
```
nmap -sV --script=ssl-heartbleed [IP]
```
```
sslyze -h [IP] --heartbleed
```

# Web Directory Enumeration
You can run this on the the top-level IP / host name or on a sub-directory/folder of interest.  Generally these sub-directories / folders of interest are the ones that show up in the robots.txt.
```
gobuster -u http(s)://[IP Address / Hostname]/[file / folder] -w [wordlist location options below] –o [output file location] -k -a '[Standard Mozilla User Agent]'
```
- /usr/share/seclists/Discovery/Web_Content/common.txt
- /usr/share/wordlists/dirbuster/directory-list-lowercase-2.3-medium.txt 

# OS Fingerprinting (ippsec:Shcoker)
Works best with Apache web servers as there are specific versions for different flavors of \*nix.
1. Get the web server service version from an Nmap service scan.  Syntax in this output is Service : Web Server Application : Web Server App Version
2. Google / use launchpad.net to identify the \*nix OS version that works with the web server version.
or
2. Go to packages.ubuntu.com, search the web server application, then cycle through the distro flavors to identify which web application pacakge version number matches the one from the HTTP service scan.  This will only fingerprint the OS distribution (not the patch level).

# Content Management Systems (CMS) Enumeration

## CMS Explorer
Used for initial fingerprinting of what CMS are used on the site.
```
cms-explorer -url http://INSERTIPADDRESS -type [Drupal, WordPress, Joomla, Mambo]
```

## Wordpress
- Wordpress usually references files using absolute paths (the full path name) instead of relative paths (just the file within the current web server directory).  We can use this behavior to view the source of webpages to identify full web server directory structure.
```
wpscan --url http://INSERTIPADDRESS --enumerate vp 
wpscan --url http://INSERTIPADDRESS --enumerate vt 
wpscan --url http://INSERTIPADDRESS --enumerate u
```
- vp: Vulnerable Plugins
- vt: Vulnerable Themes
- u: Users

## Joomscan
```
joomscan -u  http://INSERTIPADDRESS --enumerate-components
```

# Manual Method Testing
- Used to understand what methods are allowed and not allowed.
- This is generally taken care of by basic Nmap script scanning of HTTP(s) pages.
```
nc [IP] [port]
HEAD / HTTP/1.0  
OPTIONS / HTTP/1.0  
PROPFIND / HTTP/1.0  
TRACE / HTTP/1.1  
PUT http://[Target_URL]/[FILE_NAME]
POST http://[Target_URL]/[FILE_NAME] HTTP/1.x  
```

# Javascript Framework (ippsec=Node)
- If Javascript framework is used by the web application, then we can navigate to a known .js file to get a listing of connected resource pages for further analysis.
```
http://[IP]:[port]/Host/assets/js/app/app.js
```
  - You can to look at the response of this request through a web proxy to see the routes of the web application.
  - You can also navigate to this file through a web proxy site map of the web application.
